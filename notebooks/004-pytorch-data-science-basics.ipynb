{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Just a Practice Notebook for Random Data Science Stuff"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c588e4c43c6722f6"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import torch"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-02T13:51:10.630144Z",
     "start_time": "2024-05-02T13:51:08.535974Z"
    }
   },
   "id": "37eb559dc41a1498",
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X=tensor([1., 3., 4., 5.])\n",
      "Y=tensor([7., 6., 3., 1.])\n",
      "2-Norm of X: 7.141428470611572\n",
      "2-Norm of Y: 9.746794700622559\n",
      "\n",
      "Euclidean Distance: 7.874007701873779\n",
      "Manhattan Distance: 14.0\n",
      "Cosine Similarity: 0.6033958792686462\n",
      "Jaccard Similarity: 0.5\n"
     ]
    }
   ],
   "source": [
    "class Metrics():\n",
    "    def euclidean_distance(self, X, Y):\n",
    "        Z = X - Y\n",
    "        return torch.sqrt(torch.dot(Z, Z))\n",
    "         \n",
    "    def manhattan_distance(self, X, Y):\n",
    "        return torch.sum(torch.abs(X - Y))\n",
    "\n",
    "    def cosine_similarity(self, X, Y):\n",
    "        return torch.dot(X, Y) / (self.two_norm(X) * self.two_norm(Y))\n",
    "        # or even simpler with: \n",
    "        # return torch.cosine_similarity(X, Y, dim=0) \n",
    "\n",
    "    def jaccard_similarity(self, X, Y):                \n",
    "        XandY = set([e for e in X + Y])\n",
    "        XorY = set([e for e in X if e in Y])\n",
    "        return len(XorY) / len(XandY)\n",
    "        \n",
    "    def two_norm(self, X):\n",
    "        return sum(xi ** 2 for xi in X) ** 0.5\n",
    "\n",
    "X = torch.tensor([1, 3, 4, 5], dtype=torch.float32)\n",
    "Y = torch.tensor([7, 6, 3, 1], dtype=torch.float32)\n",
    "\n",
    "print(\"X={}\".format(X))\n",
    "print(\"Y={}\".format(Y))\n",
    "\n",
    "metrics = Metrics()\n",
    "print(\"2-Norm of X: {}\".format(metrics.two_norm(X)))\n",
    "print(\"2-Norm of Y: {}\".format(metrics.two_norm(Y)))\n",
    "print()\n",
    "print(\"Euclidean Distance: {}\".format(metrics.euclidean_distance(X,Y)))\n",
    "print(\"Manhattan Distance: {}\".format(metrics.manhattan_distance(X,Y)))\n",
    "print(\"Cosine Similarity: {}\".format(metrics.cosine_similarity(X,Y)))\n",
    "print(\"Jaccard Similarity: {}\".format(metrics.jaccard_similarity(X,Y)))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-02T13:51:10.655325Z",
     "start_time": "2024-05-02T13:51:10.640101Z"
    }
   },
   "id": "2fb9189a944a783e",
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Implementing KNN search and predict a binary label using KNN search"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f4f4b2866fc60010"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 3-NN of tensor([1., 3., 4., 5.]) are: ['id-1', 'id-3', 'id-6']\n",
      "The 1-NN of tensor([1., 3., 4., 5.]) is: ['id-1']\n",
      "The 2-NN of tensor([7., 6., 3., 1.]) are: ['id-2', 'id-5']\n",
      "\n",
      "The predicted label of tensor([1., 3., 4., 5.]) (with k=1) is: 1\n",
      "The predicted label of tensor([1., 3., 4., 5.]) (with k=4) is: 0\n",
      "The predicted label of tensor([7., 6., 3., 1.]) (with k=1) is: 0\n",
      "The predicted label of tensor([7., 6., 3., 1.]) (with k=4) is: 1\n"
     ]
    }
   ],
   "source": [
    "from heapq import heappush, heappop\n",
    "\n",
    "class KnnSearch:\n",
    "    \n",
    "    def predict_label(self, samples, query_vector, k, label_key=\"label\"):\n",
    "        knn = self.find_k_nearest_neighbors(samples, query_vector, k)\n",
    "        # Compute the average (binary) label of the KNN \n",
    "        return round(sum(samples[entry][label_key] for entry in knn) / len(knn))\n",
    "    \n",
    "    def find_k_nearest_neighbors(self, samples, query_vector, k):\n",
    "        # O(n log k) time and O(k) space, n = len(samples)\n",
    "        k_nearest = []\n",
    "        for sample_id, sample in samples.items():\n",
    "            d = self.l2_norm(sample['vector'], query_vector)\n",
    "            e = [-d, sample_id]\n",
    "            heappush(k_nearest, e)\n",
    "            while len(k_nearest) > k:\n",
    "                heappop(k_nearest)\n",
    "        result = []\n",
    "        while k_nearest:\n",
    "            _, sample = heappop(k_nearest)\n",
    "            result.append(sample)\n",
    "        result.reverse()\n",
    "        return result\n",
    "    \n",
    "    def l2_norm(self, vector_u , vector_v):\n",
    "        return torch.linalg.norm(vector_u - vector_v).item() # use .item() to get the value out of a 1-element + 1d-tensor\n",
    "    \n",
    "knn = KnnSearch()\n",
    "samples = {\n",
    "    'id-1': {'vector': torch.tensor([1, 3, 4, 5], dtype=torch.float32), 'label': 1},\n",
    "    'id-2': {'vector': torch.tensor([7, 6, 3, 1], dtype=torch.float32), 'label': 0},\n",
    "    'id-3': {'vector': torch.tensor([2, 3, 4, 5], dtype=torch.float32), 'label': 1},\n",
    "    'id-4': {'vector': torch.tensor([1, 3, 9, 5], dtype=torch.float32), 'label': 0},\n",
    "    'id-5': {'vector': torch.tensor([7, 2, 3, 1], dtype=torch.float32), 'label': 1},\n",
    "    'id-6': {'vector': torch.tensor([2, 3, 4, 8], dtype=torch.float32), 'label': 0},    \n",
    "}\n",
    "\n",
    "k, query = 3, torch.tensor([1, 3, 4, 5], dtype=torch.float32)\n",
    "print(\"The {}-NN of {} are:\".format(k, query), knn.find_k_nearest_neighbors(samples, query, k))\n",
    "\n",
    "k, query = 1, samples['id-1']['vector']\n",
    "print(\"The {}-NN of {} is:\".format(k, query), knn.find_k_nearest_neighbors(samples, query, k))\n",
    "\n",
    "k, query = 2, samples['id-2']['vector']\n",
    "print(\"The {}-NN of {} are:\".format(k, query), knn.find_k_nearest_neighbors(samples, query, k))\n",
    "\n",
    "print()\n",
    "\n",
    "k, query = 1, samples['id-1']['vector']\n",
    "print(\"The predicted label of {} (with k={}) is:\".format(query, k), knn.predict_label(samples, query, k))\n",
    "\n",
    "k, query = 4, samples['id-1']['vector']\n",
    "print(\"The predicted label of {} (with k={}) is:\".format(query, k), knn.predict_label(samples, query, k))\n",
    "\n",
    "k, query = 1, samples['id-2']['vector']\n",
    "print(\"The predicted label of {} (with k={}) is:\".format(query, k), knn.predict_label(samples, query, k))\n",
    "\n",
    "k, query = 4, samples['id-2']['vector']\n",
    "print(\"The predicted label of {} (with k={}) is:\".format(query, k), knn.predict_label(samples, query, k))\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-02T13:51:10.682957Z",
     "start_time": "2024-05-02T13:51:10.668474Z"
    }
   },
   "id": "fb65c9c6f833eb1e",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-02T13:51:10.698564Z",
     "start_time": "2024-05-02T13:51:10.682755Z"
    }
   },
   "id": "78d967adc8cdb320",
   "execution_count": 3
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
