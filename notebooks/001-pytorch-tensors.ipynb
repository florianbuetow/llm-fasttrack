{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# PyTorch Basics - Working with Tensors\n",
    "Here are some exercises to understand the basics of PyTorch working with tensors"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "aa26a59b7751670"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Creating Tensors\n",
    "\n",
    "... from lists and numpy arrays."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fbbbab043f81aa34"
  },
  {
   "cell_type": "code",
   "source": [
    "import os\n",
    "import torch\n",
    "\n",
    "# Tensors can be created from lists and nested lists\n",
    "a = torch.tensor([1 ,2, 3]) # 1D tensor\n",
    "b = torch.tensor([[1], [2], [3]]) # 2D tensor\n",
    "\n",
    "print(\"1D tensor A:\", a)\n",
    "print(\"2D tensor B:\", b, \"\\n\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-24T21:16:55.221910Z",
     "start_time": "2024-04-24T21:16:54.621732Z"
    }
   },
   "id": "27cbbde8186509c8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1D tensor A: tensor([1, 2, 3])\n",
      "2D tensor B: tensor([[1],\n",
      "        [2],\n",
      "        [3]]) \n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.ones((2, 3)) # works the same in numpy\n",
    "b = torch.ones(2, 3) # will throw a type error in numpy\n",
    "torch.equal(a, b)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-24T21:16:55.256573Z",
     "start_time": "2024-04-24T21:16:55.212449Z"
    }
   },
   "id": "4d0c01ebe67499aa",
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "source": [
    "# inspect the dimension of the tensors\n",
    "print(\"Dimension of tensor A:\", a.dim())\n",
    "print(\"Dimension of tensor B:\", b.dim(), \"\\n\")\n",
    "# inspect the size (==shape) of the tensors\n",
    "print(\"Shape of tensor A:\", a.size())\n",
    "print(\"Shape of tensor B:\", b.shape, \"\\n\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-24T21:16:55.447375Z",
     "start_time": "2024-04-24T21:16:55.260180Z"
    }
   },
   "id": "a76b85d66fe1d604",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimension of tensor A: 2\n",
      "Dimension of tensor B: 2 \n",
      "\n",
      "Shape of tensor A: torch.Size([2, 3])\n",
      "Shape of tensor B: torch.Size([2, 3]) \n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "cell_type": "markdown",
   "source": [
    "Note: mytensor.dim() returns len(mytensor.shape) whereas mytensor.shape tells us the number of elements in each dimension"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f601277ae6383d96"
  },
  {
   "cell_type": "code",
   "source": [
    "# inspect the data type of the tensors\n",
    "print(\"Data type of tensor A:\", a.dtype)\n",
    "print(\"Data type of tensor B:\", b.dtype, \"\\n\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-24T21:16:55.477652Z",
     "start_time": "2024-04-24T21:16:55.435089Z"
    }
   },
   "id": "f4b3bfef79126708",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data type of tensor A: torch.float32\n",
      "Data type of tensor B: torch.float32 \n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.ones(1,2,3,dtype=torch.long)\n",
    "b = torch.ones((1,2,3), dtype=torch.float32)\n",
    "torch.equal(a, b) # will return true because the values of the tensors are the same"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-24T21:16:55.600637Z",
     "start_time": "2024-04-24T21:16:55.481982Z"
    }
   },
   "id": "9917ba2c30e76096",
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "source": [
    "# Tensors can also be created from NumPy arrays\n",
    "import numpy as np\n",
    "\n",
    "my_np_array = np.array([1, 2, 3])\n",
    "a = torch.tensor(my_np_array) # pass the np array into the tensor function\n",
    "b = torch.from_numpy(my_np_array) # or use the from_numpy function, the result is the same\n",
    "print(\"1D tensor A from numpy array:\", a)\n",
    "print(\"1D tensor B from numpy array:\", b)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-24T21:16:55.640080Z",
     "start_time": "2024-04-24T21:16:55.557891Z"
    }
   },
   "id": "8a2d752a65840dd7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1D tensor A from numpy array: tensor([1, 2, 3])\n",
      "1D tensor B from numpy array: tensor([1, 2, 3])\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Convenience methods for creating special kinds of tensors"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3f70c77b66e67d53"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4743, 0.4855, 0.5064],\n",
      "        [0.7785, 0.9350, 0.9388]])\n",
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "# Define a tensor by specifying its shape\n",
    "shape = (2, 3)\n",
    "tensor = torch.rand(shape)\n",
    "print(tensor)\n",
    "# Create a new tensor with the same shape as an existing tensor\n",
    "tensor_with_same_dimensions = torch.ones_like(tensor)\n",
    "print(tensor_with_same_dimensions)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-24T21:16:55.763848Z",
     "start_time": "2024-04-24T21:16:55.632346Z"
    }
   },
   "id": "33e05252dc889348",
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "source": [
    "identity_tensor = torch.eye(5) # creates a 2-dimensional tensor, a 5x5 identity matrix (ones on the diagonal, zeros elsewhere)\n",
    "identity_tensor"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-24T21:16:55.861381Z",
     "start_time": "2024-04-24T21:16:55.768011Z"
    }
   },
   "id": "329b97ae9643f2f0",
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[1., 0., 0., 0., 0.],\n        [0., 1., 0., 0., 0.],\n        [0., 0., 1., 0., 0.],\n        [0., 0., 0., 1., 0.],\n        [0., 0., 0., 0., 1.]])"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 20
  },
  {
   "cell_type": "code",
   "source": [
    "zero_tensor = torch.zeros(3, 10) # creates a 2-dimensional tensor, a 3x10 matrix filled with zeros\n",
    "zero_tensor"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-24T21:16:55.986781Z",
     "start_time": "2024-04-24T21:16:55.842838Z"
    }
   },
   "id": "2365ece098efc413",
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "source": [
    "ones_tensor = torch.ones(5, 2) # creates a 2-dimensional tensor, a 5x2 matrix filled with ones\n",
    "ones_tensor"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-24T21:16:56.051365Z",
     "start_time": "2024-04-24T21:16:55.936782Z"
    }
   },
   "id": "2f8a8616023e2dd4",
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[1., 1.],\n        [1., 1.],\n        [1., 1.],\n        [1., 1.],\n        [1., 1.]])"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 22
  },
  {
   "cell_type": "markdown",
   "source": [
    "Note: with any of the above functions, you can specify multiple parameters to create tensors of higher dimensions (in the examples we only created 2D tensors)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "226e4a6cfddc8c0b"
  },
  {
   "cell_type": "code",
   "source": [
    "random_tensor = torch.rand(2, 2, 3) # creates a 2-dimensional tensor, a 3x4 matrix filled with random numbers between 0 and 1\n",
    "random_tensor"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-24T21:16:56.203791Z",
     "start_time": "2024-04-24T21:16:56.058127Z"
    }
   },
   "id": "bac84fb0bbb10c7c",
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[[0.1318, 0.9701, 0.8058],\n         [0.3675, 0.5721, 0.6123]],\n\n        [[0.3549, 0.0137, 0.8374],\n         [0.9829, 0.2530, 0.8167]]])"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 23
  },
  {
   "cell_type": "code",
   "source": [
    "random_normal_tensor = torch.randn(20) # creates a 1-dimensional tensor, a 20-element vector filled with random numbers from a normal distribution\n",
    "random_normal_tensor"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-24T21:16:56.263705Z",
     "start_time": "2024-04-24T21:16:56.149748Z"
    }
   },
   "id": "ba05d7d470e386ba",
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([ 1.2962, -0.9009, -0.3100,  1.2851, -0.4065, -0.0651,  0.1218,  1.7723,\n         0.0178,  0.3439,  1.0905,  0.8004, -0.6779,  0.3521, -0.4445,  0.3229,\n        -0.5456, -0.3716,  0.6859, -0.3019])"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 24
  },
  {
   "cell_type": "markdown",
   "source": [
    "Reminder: Normal distribution means that the mean is 0 and the variance is 1"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fb51294d1344527a"
  },
  {
   "cell_type": "code",
   "source": [
    "# we can also create a tensor filled with random integers\n",
    "random_int_tensor = torch.randint(low=5, high=10, size=(5, 5)) # creates a 2-dimensional tensor, a 5x5 matrix filled with random integers between 0 and 10\n",
    "random_int_tensor"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-24T21:16:56.345848Z",
     "start_time": "2024-04-24T21:16:56.267679Z"
    }
   },
   "id": "488a63bddd00ac8b",
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[7, 9, 5, 8, 6],\n        [6, 6, 6, 5, 9],\n        [5, 7, 9, 9, 5],\n        [6, 9, 8, 8, 8],\n        [6, 8, 6, 7, 6]])"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 25
  },
  {
   "cell_type": "code",
   "source": [
    "# pytorch also allows to create a tensor filled with a range of numbers\n",
    "range_tensor = torch.arange(3, 17) # creates a 1-dimensional tensor, a 14-element vector filled with numbers from 3 to 16\n",
    "range_tensor"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-24T21:16:56.437376Z",
     "start_time": "2024-04-24T21:16:56.332140Z"
    }
   },
   "id": "6a4efc8781c28a57",
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([ 3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16])"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 26
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Working with tensor metadata\n",
    "\n",
    "We alredy learned about .dim() .shape and .dtype. Here are some more useful tensor attributes:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5703b4ac2b238ede"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-24T21:16:56.545358Z",
     "start_time": "2024-04-24T21:16:56.440669Z"
    }
   },
   "cell_type": "code",
   "source": [
    "my_tensor = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
    "print(my_tensor.numel()) # returns the number of elements in the tensor\n",
    "print(my_tensor.nelement())"
   ],
   "id": "8a67835fe5ae24a1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n",
      "9\n"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-24T21:16:56.652410Z",
     "start_time": "2024-04-24T21:16:56.543216Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "False"
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 28,
   "source": [
    "# Check if cuda is enabled\n",
    "my_tensor.is_cuda # returns true if the tensor is stored on the GPU"
   ],
   "id": "33a82c7bf4e4f65c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-24T21:16:56.674295Z",
     "start_time": "2024-04-24T21:16:56.636658Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Get the device on which the tensor is stored on (you could have multiple GPUs)\n",
    "my_tensor.device"
   ],
   "id": "78b2ffadd6da5b06",
   "outputs": [
    {
     "data": {
      "text/plain": "device(type='cpu')"
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Tensor Types and Casting\n",
    "\n",
    "PyTorch defines its own data type, which can be used to create tensors. The default data type is float32. You can change the data type of the tensor using the .to() method. \n",
    "\n",
    "\n",
    "| Data Type                | dtype                       | CPU tensor       | GPU tensor              |\n",
    "|--------------------------|-----------------------------|------------------|-------------------------|\n",
    "| 32-bit floating point    | torch.float32/torch.float   | torch.FloatTensor| torch.cuda.FloatTensor  |\n",
    "| 64-bit floating point    | torch.float64/torch.double  | torch.DoubleTensor| torch.cuda.DoubleTensor|\n",
    "| 8-bit integer (signed)   | torch.int16                 | torch.ShortTensor| torch.cuda.ShortTensor  |\n",
    "| boolean                  | torch.bool                  | torch.BoolTensor | torch.cuda.BoolTensor   |\n",
    "\n",
    "\n"
   ],
   "id": "3607fd9fbd80f0d1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-24T21:16:56.783161Z",
     "start_time": "2024-04-24T21:16:56.679349Z"
    }
   },
   "cell_type": "code",
   "source": [
    "my_tensor = torch.tensor([1, 1, 1, 1])\n",
    "print(\"The dtype of my_tensor is {}\".format(my_tensor.dtype))\n",
    "\n",
    "my_tensor = torch.tensor([1, 2, 3, 4], dtype=torch.float)\n",
    "print(\"The dtype of my_tensor is {}\".format(my_tensor.dtype))"
   ],
   "id": "f8a81d53456fce2d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dtype of my_tensor is torch.int64\n",
      "The dtype of my_tensor is torch.float32\n"
     ]
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-24T21:16:56.833904Z",
     "start_time": "2024-04-24T21:16:56.767147Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float32\n",
      "torch.int32\n",
      "torch.float64\n",
      "torch.int64\n"
     ]
    }
   ],
   "execution_count": 31,
   "source": [
    "# Pytorch has some conevience methods to create tensors with a specific data type\n",
    "tensor_float32 = torch.FloatTensor([1, 2, 3, 4])\n",
    "print(tensor_float32.dtype)\n",
    "tensor_int32 = torch.IntTensor([1, 2, 3, 4])\n",
    "print(tensor_int32.dtype)\n",
    "tensor_float64 = torch.DoubleTensor([1, 2, 3, 4])\n",
    "print(tensor_float64.dtype)\n",
    "tensor_int64 = torch.LongTensor([1, 2, 3, 4])\n",
    "print(tensor_int64.dtype)"
   ],
   "id": "2c819908912709df"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.int32\n",
      "torch.float32\n"
     ]
    }
   ],
   "source": [
    "# Casting tensors to a different data type by calling the .to() method on the tensor\n",
    "tensor = tensor_float32.to(dtype=torch.int32)\n",
    "print(tensor.dtype)\n",
    "tensor = tensor.to(dtype=torch.float32)\n",
    "print(tensor.dtype)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-24T21:16:56.981448Z",
     "start_time": "2024-04-24T21:16:56.839700Z"
    }
   },
   "id": "29bf56cff6f22c7",
   "execution_count": 32
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAssertionError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[33], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# It is possible to cast tensors to different devices (CPU or GPU)\u001B[39;00m\n\u001B[0;32m----> 2\u001B[0m tensor \u001B[38;5;241m=\u001B[39m \u001B[43mtensor\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mto\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdevice\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mcuda\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/projects/LLM-FastTrack/.venv/lib/python3.11/site-packages/torch/cuda/__init__.py:293\u001B[0m, in \u001B[0;36m_lazy_init\u001B[0;34m()\u001B[0m\n\u001B[1;32m    288\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\n\u001B[1;32m    289\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCannot re-initialize CUDA in forked subprocess. To use CUDA with \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    290\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmultiprocessing, you must use the \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mspawn\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m start method\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    291\u001B[0m     )\n\u001B[1;32m    292\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(torch\u001B[38;5;241m.\u001B[39m_C, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_cuda_getDeviceCount\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[0;32m--> 293\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mAssertionError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTorch not compiled with CUDA enabled\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    294\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m _cudart \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    295\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mAssertionError\u001B[39;00m(\n\u001B[1;32m    296\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlibcudart functions unavailable. It looks like you have a broken build?\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    297\u001B[0m     )\n",
      "\u001B[0;31mAssertionError\u001B[0m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "source": [
    "# It is possible to cast tensors to different devices (CPU or GPU)\n",
    "tensor = tensor.to(device='cuda')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-24T21:16:57.233859Z",
     "start_time": "2024-04-24T21:16:56.969357Z"
    }
   },
   "id": "e6ab4b0daea5f5dd",
   "execution_count": 33
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Or better: :)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "tensor = tensor.to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-24T21:16:57.206242Z"
    }
   },
   "id": "866e80d4395b5e06",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Selecting Elements from a Tensor\n",
    "\n",
    "This works similar to numpy arrays"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9949462e15c97da5"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# reshape a 1D tensor to a 2D tensor\n",
    "tensor = torch.arange(0, 16)\n",
    "print(\"Original tensor:\", tensor)\n",
    "tensor = tensor.reshape((4, 4)) # the product of the dimensions must be equal to the number of elements in the tensor\n",
    "print(\"Reshaped tensor:\", tensor)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-24T21:16:57.210934Z"
    }
   },
   "id": "b5077047d8208e56",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "for i in range(tensor.shape[0]):\n",
    "    for j in range(tensor.shape[1]):\n",
    "        print(tensor[i, j], end=\" \")\n",
    "    print()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-24T21:16:57.215094Z"
    }
   },
   "id": "90bc452a1cf10638",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# One can even select rows and columns (!)\n",
    "print(\"First row:\",tensor[0, :]) # select the first row\n",
    "print(\"Seocnd column:\", tensor[:, 1]) # select the first column"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-24T21:16:57.216929Z"
    }
   },
   "id": "742e4005343c67eb",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Selecting elements from a tensor with index_select\n",
    "This allows us to select elements from a tensor based on the indices we provide"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4d918e49882d2b7a"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0,  1,  2,  3],\n",
      "        [ 4,  5,  6,  7],\n",
      "        [ 8,  9, 10, 11],\n",
      "        [12, 13, 14, 15]])\n",
      "tensor([[ 0,  3],\n",
      "        [ 4,  7],\n",
      "        [ 8, 11],\n",
      "        [12, 15]])\n",
      "tensor([[ 0,  1,  2,  3],\n",
      "        [12, 13, 14, 15]])\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.arange(0, 16).reshape((4,4))\n",
    "indices = torch.tensor([0, 3]) # select the first and last column \n",
    "columns = tensor.index_select(dim=1, index=indices) # dim = 0 for rows, dim is the dimension in which we index\n",
    "rows =  tensor.index_select(dim=0, index=indices) # dim = 1 for columns, dim is the dimension in which we index\n",
    "print(tensor)\n",
    "print(columns)\n",
    "print(rows)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-24T21:16:57.751954Z",
     "start_time": "2024-04-24T21:16:57.243024Z"
    }
   },
   "id": "6c14aff9553fe17c",
   "execution_count": 34
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0,  1,  2,  3],\n",
      "        [ 4,  5,  6,  7],\n",
      "        [ 8,  9, 10, 11],\n",
      "        [12, 13, 14, 15]]) \n",
      "\n",
      "tensor(5) \n",
      "\n",
      "tensor([ 8,  9, 10, 11]) \n",
      "\n",
      "tensor([[ 0],\n",
      "        [ 4],\n",
      "        [ 8],\n",
      "        [12]]) \n",
      "\n",
      "tensor([[ 8,  9],\n",
      "        [12, 13]]) \n",
      "\n",
      "tensor([[2, 3],\n",
      "        [6, 7]]) \n"
     ]
    }
   ],
   "source": [
    "tensor = torch.arange(0,16).reshape(4,4)\n",
    "print(tensor,\"\\n\")\n",
    "print(tensor[1,1],\"\\n\") # select a single element\n",
    "print(tensor[2,:],\"\\n\") # select a row\n",
    "print(tensor[:,0].reshape(4,1),\"\\n\") # select a column\n",
    "print(tensor[2:,:2],\"\\n\") # select the lower bottom submatrix (row 3 and 4, column 1 and 2)\n",
    "print(tensor[0:2,2:4],\"\\n\") # select the top right submatrix (row 0 and 1, column 2 to 3)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-24T21:16:57.813454Z",
     "start_time": "2024-04-24T21:16:57.571625Z"
    }
   },
   "id": "176dd097d6145f80",
   "execution_count": 35
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Selecting elements from a Tensor with a mask\n",
    "This is pretty cool, we can create a BoolTensor as a mask to select which elements we want to select from a tensor. "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d657d6d90c8e67ab"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 1, 2],\n",
      "        [3, 4, 5],\n",
      "        [6, 7, 8]])\n",
      "tensor([[ True, False,  True],\n",
      "        [False,  True, False],\n",
      "        [ True, False,  True]])\n",
      "tensor([0, 2, 4, 6, 8])\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.arange(0, 9).reshape((3,3))\n",
    "print(tensor)\n",
    "mask = torch.BoolTensor([\n",
    "    [1, 0, 1],  # 1 or True means we select the element\n",
    "    [0, 1, 0], \n",
    "    [1, 0, True]\n",
    "])\n",
    "# Alternative way of defining the mask: mask = torch.BoolTensor([1, 0, 1, 0, 1, 1, 1, 0, 1]).reshape(3,3)\n",
    "print(mask)\n",
    "selection = torch.masked_select(tensor, mask) # returns a 1D tensor with the elements that are True in the mask\n",
    "print(selection)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-24T21:16:58.087748Z",
     "start_time": "2024-04-24T21:16:57.798880Z"
    }
   },
   "id": "3b267d4bdbe673f0",
   "execution_count": 36
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Reshaping Tensors"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a224cd569b722cd1"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original tensor: tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15],\n",
      "       dtype=torch.int8)\n",
      "Shape of the original tensor: torch.Size([16])\n",
      "Reshaped tensor: tensor([[ 0,  1,  2,  3],\n",
      "        [ 4,  5,  6,  7],\n",
      "        [ 8,  9, 10, 11],\n",
      "        [12, 13, 14, 15]], dtype=torch.int8)\n",
      "Shape of the reshaped tensor: torch.Size([4, 4])\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.arange(0, 16, dtype=torch.int8)\n",
    "print(\"Original tensor:\", tensor)\n",
    "print(\"Shape of the original tensor:\", tensor.shape)\n",
    "tensor = torch.reshape(tensor, (4,4))\n",
    "# or tensor = tensor.reshape((4,4))\n",
    "print(\"Reshaped tensor:\", tensor)\n",
    "print(\"Shape of the reshaped tensor:\", tensor.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-24T21:16:58.169888Z",
     "start_time": "2024-04-24T21:16:58.045084Z"
    }
   },
   "id": "93e47030cafbf0b6",
   "execution_count": 37
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reshaped tensor: tensor([[ 0,  1],\n",
      "        [ 2,  3],\n",
      "        [ 4,  5],\n",
      "        [ 6,  7],\n",
      "        [ 8,  9],\n",
      "        [10, 11],\n",
      "        [12, 13],\n",
      "        [14, 15]], dtype=torch.int8)\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.reshape(tensor, (-1, 2)) # the -1 is a placeholder for the dimension that is inferred from the length of the tensor and the other dimensions\n",
    "print(\"Reshaped tensor:\", tensor)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-24T21:16:58.378919Z",
     "start_time": "2024-04-24T21:16:58.158838Z"
    }
   },
   "id": "c103b67e2695b182",
   "execution_count": 38
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Squeeze and Un-squeeze\n",
    "\n",
    "Allows us to remove and add dimensions of size 1 to a tensor.\n",
    "In numpy expand_dims() and squeeze() are used for the same purpose."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9c994a1b06b0b856"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original tensor: tensor([[[ 0,  1,  2,  3],\n",
      "         [ 4,  5,  6,  7],\n",
      "         [ 8,  9, 10, 11],\n",
      "         [12, 13, 14, 15]]])\n",
      "Shape of the original tensor: torch.Size([1, 4, 4])\n",
      "\n",
      "Squeezed tensor: tensor([[ 0,  1,  2,  3],\n",
      "        [ 4,  5,  6,  7],\n",
      "        [ 8,  9, 10, 11],\n",
      "        [12, 13, 14, 15]])\n",
      "Shape of the squeezed tensor: torch.Size([4, 4])\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.arange(0, 16).reshape((1, 4, 4))\n",
    "print(\"Original tensor:\", tensor)\n",
    "print(\"Shape of the original tensor:\", tensor.shape)\n",
    "tensor = torch.squeeze(tensor) # removes all dimensions with size 1\n",
    "print(\"\\nSqueezed tensor:\", tensor)\n",
    "print(\"Shape of the squeezed tensor:\", tensor.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-24T21:16:58.432932Z",
     "start_time": "2024-04-24T21:16:58.336570Z"
    }
   },
   "id": "69d9aeffbfe029ce",
   "execution_count": 39
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original tensor: tensor([[ 0,  1,  2,  3],\n",
      "        [ 4,  5,  6,  7],\n",
      "        [ 8,  9, 10, 11],\n",
      "        [12, 13, 14, 15]])\n",
      "Shape of the original tensor: torch.Size([4, 4])\n",
      "\n",
      "Un-squeezed tensor: tensor([[[ 0,  1,  2,  3]],\n",
      "\n",
      "        [[ 4,  5,  6,  7]],\n",
      "\n",
      "        [[ 8,  9, 10, 11]],\n",
      "\n",
      "        [[12, 13, 14, 15]]])\n",
      "Shape of the un-squeezed tensor: torch.Size([4, 1, 4])\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.arange(0, 16).reshape((4, 4))\n",
    "print(\"Original tensor:\", tensor)\n",
    "print(\"Shape of the original tensor:\", tensor.shape)\n",
    "tensor = torch.unsqueeze(tensor, 1) # adds a dimension at the specified index\n",
    "print(\"\\nUn-squeezed tensor:\", tensor)\n",
    "print(\"Shape of the un-squeezed tensor:\", tensor.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-24T21:16:58.570237Z",
     "start_time": "2024-04-24T21:16:58.415718Z"
    }
   },
   "id": "337660c828f10657",
   "execution_count": 40
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the original tensor: torch.Size([3, 1, 2, 1, 2])\n",
      "Shape of the squeezed tensor: torch.Size([3, 2, 1, 2])\n",
      "Shape of the squeezed tensor: torch.Size([3, 2, 2])\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.ones((3,1,2,1,2))\n",
    "print(\"Shape of the original tensor:\", tensor.shape)\n",
    "tensor = torch.squeeze(tensor, dim=1) # will only work on dimensions of size 1 (in this case the second dimension)\n",
    "print(\"Shape of the squeezed tensor:\", tensor.shape)\n",
    "tensor = torch.squeeze(tensor) # remove all remaining dimensions of size 1\n",
    "print(\"Shape of the squeezed tensor:\", tensor.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-24T21:16:58.635267Z",
     "start_time": "2024-04-24T21:16:58.557148Z"
    }
   },
   "id": "f1004f60ec1a0011",
   "execution_count": 41
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Transposing Tensors"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "60a16083cb5c8f0c"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original tensor: tensor([[1, 2],\n",
      "        [0, 1]])\n",
      "\n",
      "Transposed tensor: tensor([[1, 0],\n",
      "        [2, 1]])\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.tensor([[1,2], [0,1]])\n",
    "print(\"Original tensor:\", tensor)\n",
    "tensor = torch.transpose(tensor, 0, 1) # swaps the dimensions at index 0 and 1\n",
    "print(\"\\nTransposed tensor:\", tensor)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-24T21:16:58.785717Z",
     "start_time": "2024-04-24T21:16:58.624103Z"
    }
   },
   "id": "2955998781131203",
   "execution_count": 42
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the original tensor: torch.Size([2, 3])\n",
      "Shape of the transposed tensor: torch.Size([3, 2])\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.zeros(2,3)\n",
    "print(\"Shape of the original tensor:\", tensor.shape)\n",
    "tensor = torch.transpose(tensor, 0, 1) # swaps the dimensions at index 0 and 1\n",
    "print(\"Shape of the transposed tensor:\", tensor.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-24T21:16:58.872233Z",
     "start_time": "2024-04-24T21:16:58.789041Z"
    }
   },
   "id": "943b42b0086a671b",
   "execution_count": 43
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Concatenating Tensors"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cc6acd1075a10233"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0.],\n",
      "        [0., 0.]])\n",
      "tensor([[1., 1.],\n",
      "        [1., 1.]])\n",
      "tensor([[0., 0., 1., 1.],\n",
      "        [0., 0., 1., 1.]])\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.],\n",
      "        [1., 1.],\n",
      "        [1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.zeros(2,2)\n",
    "b = torch.ones(2,2)\n",
    "c = torch.concat([a, b], dim=1) # concat along the columns\n",
    "d = torch.concat([a, b], dim=0) # concat along the rows\n",
    "print(a)\n",
    "print(b)\n",
    "print(c)\n",
    "print(d)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-24T21:16:58.939638Z",
     "start_time": "2024-04-24T21:16:58.840469Z"
    }
   },
   "id": "9becb5dd1d70f3cd",
   "execution_count": 44
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Stacking Tensors\n",
    "\n",
    "Using torch.cat() and torch.stack().\n",
    "torch.cat() stacks tensors along an existing dimension, whereas torch.stack() stacks tensors along a new dimension."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f987e78ed3bef168"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor A: tensor([[1., 1.],\n",
      "        [1., 1.]])\n",
      "Shape of tensor A: torch.Size([2, 2])\n",
      "\n",
      "Tensor B: tensor([[0., 0.],\n",
      "        [0., 0.]])\n",
      "Shape of tensor B: torch.Size([2, 2])\n",
      "\n",
      "Stacked tensor: tensor([[[1., 1.],\n",
      "         [1., 1.]],\n",
      "\n",
      "        [[0., 0.],\n",
      "         [0., 0.]]])\n",
      "Shape of the stacked tensor: torch.Size([2, 2, 2])\n",
      "\n",
      "Concatenated tensor: tensor([[1., 1.],\n",
      "        [1., 1.],\n",
      "        [0., 0.],\n",
      "        [0., 0.]])\n",
      "Shape of the concatenated tensor: torch.Size([4, 2])\n",
      "\n",
      "Concatenated tensor: tensor([[1., 1., 0., 0.],\n",
      "        [1., 1., 0., 0.]])\n",
      "Shape of the concatenated tensor: torch.Size([2, 4])\n"
     ]
    }
   ],
   "source": [
    "a = torch.ones(2,2)\n",
    "b = torch.zeros(2,2)\n",
    "print(\"Tensor A:\", a)\n",
    "print(\"Shape of tensor A:\", a.shape)\n",
    "print(\"\\nTensor B:\", b)\n",
    "print(\"Shape of tensor B:\", b.shape)\n",
    "c = torch.stack([a, b], dim=0) # stack along a new dimension\n",
    "print(\"\\nStacked tensor:\", c)\n",
    "print(\"Shape of the stacked tensor:\", c.shape)\n",
    "d = torch.cat([a, b], dim=0) # concatenate along an existing dimension (here: rows)\n",
    "print(\"\\nConcatenated tensor:\", d)\n",
    "print(\"Shape of the concatenated tensor:\", d.shape)\n",
    "e = torch.cat([a, b], dim=1) # concatenate along an existing dimension (here: rows)\n",
    "print(\"\\nConcatenated tensor:\", e)\n",
    "print(\"Shape of the concatenated tensor:\", e.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-24T21:16:58.989178Z",
     "start_time": "2024-04-24T21:16:58.923915Z"
    }
   },
   "id": "aa86e977b71d2d5",
   "execution_count": 45
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Element-wise operations on Tensors"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c0bdb66c356bf0cc"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original tensor: tensor([1, 2, 3])\n",
      "Tensor after adding 2 to each element: tensor([3, 4, 5])\n",
      "Tensor after multiplying each element by 2: tensor([ 6,  8, 10])\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.tensor([1,2,3])\n",
    "print(\"Original tensor:\", tensor)\n",
    "tensor += 1 # this adds 1 to each element of the tensor in-place\n",
    "tensor.add(1) # this returns a new tensor, add does not change the original tensor in-place\n",
    "tensor.add_(1) # this however changes the original tensor in-place (same as tensor += 1)\n",
    "print(\"Tensor after adding 2 to each element:\", tensor)\n",
    "tensor *= 2 \n",
    "print(\"Tensor after multiplying each element by 2:\", tensor)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-24T21:16:59.121465Z",
     "start_time": "2024-04-24T21:16:58.983907Z"
    }
   },
   "id": "55a2bafd2ab176bc",
   "execution_count": 46
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor A: tensor([[0, 1],\n",
      "        [2, 3]])\n",
      "Tensor B: tensor([[2., 2.],\n",
      "        [2., 2.]])\n",
      "Tensor C: tensor([[2., 3.],\n",
      "        [4., 5.]])\n",
      "Tensor D: tensor([[0., 2.],\n",
      "        [4., 6.]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.arange(0, 4).reshape(2, 2)\n",
    "b = torch.ones(2,2).reshape(2, 2)\n",
    "b += 1\n",
    "c = a + b # element-wise addition\n",
    "d = a * b # element-wise multiplication\n",
    "print(\"Tensor A:\", a)\n",
    "print(\"Tensor B:\", b)\n",
    "print(\"Tensor C:\", c)\n",
    "print(\"Tensor D:\", d)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-24T21:16:59.173487Z",
     "start_time": "2024-04-24T21:16:59.099642Z"
    }
   },
   "id": "cf02961006ffe33d",
   "execution_count": 47
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Reduction and Comparison Operations\n",
    "\n",
    "PyTorch offers a variety of reduction operations that can be applied to tensors.\n",
    "Unless the argument dim is specified, the operation is applied to all elements of the tensor.\n",
    "\n",
    "| Function | Description |\n",
    "|----------|-------------|\n",
    "| mean()   | Computes the mean of all elements in the tensor |\n",
    "| sum()    | Computes the sum of all elements in the tensor |\n",
    "| max()    | Returns the maximum value in the tensor |\n",
    "| min()    | Returns the minimum value in the tensor |\n",
    "| argmax() | Returns the index of the maximum value in the tensor |\n",
    "| argmin() | Returns the index of the minimum value in the tensor |\n",
    "| eq()     | Element-wise comparison, returns a tensor with True where the elements are equal |\n",
    "| lt()     | Element-wise comparison, returns a tensor with True where the elements are less than |\n",
    "| gt()     | Element-wise comparison, returns a tensor with True where the elements are greater than |\n",
    "| le()     | Element-wise comparison, returns a tensor with True where the elements are less than or equal |\n",
    "| ge()     | Element-wise comparison, returns a tensor with True where the elements are greater than or equal |\n",
    "| ne()     | Element-wise comparison, returns a tensor with True where the elements are not equal |\n",
    "| median() | Returns the median of all elements in the tensor |\n",
    "| mode()   | Returns the mode of all elements in the tensor |\n",
    "| std()    | Returns the standard deviation of all elements in the tensor |\n",
    "| var()    | Returns the variance of all elements in the tensor |\n",
    "| all()    | Returns True if all elements in the tensor are True |\n",
    "| any()    | Returns True if any element in the tensor is True |\n",
    "| prod()   | Returns the product of all elements in the tensor |\n",
    "| unique() | Returns the unique elements in the tensor |\n",
    "| cumsum() | Returns the cumulative sum of the elements in the tensor |\n",
    "| cumprod()| Returns the cumulative product of the elements in the tensor |\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ff58250859f94e30"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original tensor: tensor([[0., 1., 2.],\n",
      "        [3., 4., 5.],\n",
      "        [6., 7., 8.]])\n",
      "\n",
      "torch.mean(tensor) is: tensor(4.)\n",
      "\n",
      "torch.mean(tensor, dim=0) is: tensor([3., 4., 5.])\n",
      "\n",
      "torch.mean(tensor, dim=1) is: tensor([1., 4., 7.])\n",
      "\n",
      "torch.sum(tensor) is: tensor(36.)\n",
      "\n",
      "torch.max(tensor) is: tensor(8.)\n",
      "\n",
      "torch.min(tensor) is: tensor(0.)\n",
      "\n",
      "torch.median(tensor) is: tensor(4.)\n",
      "\n",
      "torch.mode(tensor) is: torch.return_types.mode(\n",
      "values=tensor([0., 3., 6.]),\n",
      "indices=tensor([0, 0, 0]))\n",
      "\n",
      "torch.std(tensor) is: tensor(2.7386)\n",
      "\n",
      "torch.var(tensor) is: tensor(7.5000)\n",
      "\n",
      "torch.all(tensor) is: tensor(False)\n",
      "\n",
      "torch.prod(tensor) is: tensor(0.)\n",
      "\n",
      "torch.cumsum(tensor, dim=1) is: tensor([[ 0.,  1.,  3.],\n",
      "        [ 3.,  7., 12.],\n",
      "        [ 6., 13., 21.]])\n",
      "\n",
      "torch.cumprod(tensor, dim=0) is: tensor([[ 0.,  1.,  2.],\n",
      "        [ 0.,  4., 10.],\n",
      "        [ 0., 28., 80.]])\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.arange(0, 9, dtype=torch.float32).reshape(3,3)\n",
    "print(\"Original tensor:\", tensor)\n",
    "print(\"\\ntorch.mean(tensor) is:\",torch.mean(tensor))\n",
    "print(\"\\ntorch.mean(tensor, dim=0) is:\",torch.mean(tensor, dim=0)) # returns the mean of the elements in the tensor for each column\n",
    "print(\"\\ntorch.mean(tensor, dim=1) is:\",torch.mean(tensor, dim=1)) # returns the mean of the elements in the tensor for each row\n",
    "print(\"\\ntorch.sum(tensor) is:\",torch.sum(tensor))\n",
    "print(\"\\ntorch.max(tensor) is:\",torch.max(tensor))\n",
    "print(\"\\ntorch.min(tensor) is:\",torch.min(tensor))\n",
    "print(\"\\ntorch.median(tensor) is:\",torch.median(tensor))\n",
    "print(\"\\ntorch.mode(tensor) is:\",torch.mode(tensor))\n",
    "print(\"\\ntorch.std(tensor) is:\",torch.std(tensor))\n",
    "print(\"\\ntorch.var(tensor) is:\",torch.var(tensor))\n",
    "print(\"\\ntorch.all(tensor) is:\",torch.all(tensor))\n",
    "print(\"\\ntorch.prod(tensor) is:\",torch.prod(tensor)) # returns the product of all elements in the tensor\n",
    "print(\"\\ntorch.cumsum(tensor, dim=1) is:\",torch.cumsum(tensor, dim=1)) # returns the cumulative sum of the elements in the tensor for each row\n",
    "print(\"\\ntorch.cumprod(tensor, dim=0) is:\",torch.cumprod(tensor, dim=0)) # returns the cumulative product of the elements in the tensor for each column\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-24T21:16:59.313445Z",
     "start_time": "2024-04-24T21:16:59.167309Z"
    }
   },
   "id": "969e417faf02c57d",
   "execution_count": 48
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original tensor: tensor([[0, 1],\n",
      "        [2, 0]])\n",
      "\n",
      "torch.argmax(tensor) is: tensor(2)\n",
      "\n",
      "torch.argmin(tensor) is: tensor(0)\n",
      "\n",
      "torch.any(tensor) is: tensor(True)\n",
      "\n",
      "torch.unique(tensor) is: tensor([0, 1, 2])\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.LongTensor([0,1,2,0]).reshape(2,2)\n",
    "print(\"Original tensor:\", tensor)\n",
    "print(\"\\ntorch.argmax(tensor) is:\",torch.argmax(tensor))\n",
    "print(\"\\ntorch.argmin(tensor) is:\",torch.argmin(tensor))\n",
    "print(\"\\ntorch.any(tensor) is:\",torch.any(tensor)) # returns True if any element in the tensor is True\n",
    "print(\"\\ntorch.unique(tensor) is:\",torch.unique(tensor)) # returns the unique elements in the tensor"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-24T21:17:00.366109Z",
     "start_time": "2024-04-24T21:16:59.298605Z"
    }
   },
   "id": "38380e416985c3f2",
   "execution_count": 49
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original tensor: tensor([[0., 1., 2.],\n",
      "        [3., 4., 5.],\n",
      "        [6., 7., 8.]])\n",
      "\n",
      "Another tensor: tensor([[1., 1., 2.],\n",
      "        [3., 4., 5.],\n",
      "        [6., 7., 8.]])\n",
      "\n",
      "tensor.eq() is: tensor([[False,  True,  True],\n",
      "        [ True,  True,  True],\n",
      "        [ True,  True,  True]])\n",
      "\n",
      "tensor.lt() is: tensor([[ True, False, False],\n",
      "        [False, False, False],\n",
      "        [False, False, False]])\n",
      "\n",
      "tensor.gt() is: tensor([[False, False, False],\n",
      "        [False, False, False],\n",
      "        [False, False, False]])\n",
      "\n",
      "tensor.le() is: tensor([[True, True, True],\n",
      "        [True, True, True],\n",
      "        [True, True, True]])\n",
      "\n",
      "tensor.ge() is: tensor([[False,  True,  True],\n",
      "        [ True,  True,  True],\n",
      "        [ True,  True,  True]])\n",
      "\n",
      "tensor.ne() is: tensor([[ True, False, False],\n",
      "        [False, False, False],\n",
      "        [False, False, False]])\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.arange(0, 9, dtype=torch.float32).reshape(3,3)\n",
    "# copy tensor\n",
    "another_tensor = tensor.clone() # creates a copy of the tensor\n",
    "another_tensor[0,0] = 1\n",
    "print(\"Original tensor:\", tensor)\n",
    "print(\"\\nAnother tensor:\", another_tensor)\n",
    "print(\"\\ntensor.eq() is:\",tensor.eq(another_tensor))\n",
    "print(\"\\ntensor.lt() is:\",tensor.lt(another_tensor))\n",
    "print(\"\\ntensor.gt() is:\",tensor.gt(another_tensor))\n",
    "print(\"\\ntensor.le() is:\",tensor.le(another_tensor))\n",
    "print(\"\\ntensor.ge() is:\",tensor.ge(another_tensor))\n",
    "print(\"\\ntensor.ne() is:\",tensor.ne(another_tensor))\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-24T21:17:00.477379Z",
     "start_time": "2024-04-24T21:17:00.167841Z"
    }
   },
   "id": "8c53d07d94b1835a",
   "execution_count": 50
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The original tensor is \n",
      " tensor([[ 1.7810,  1.4539, -1.3121, -0.0098],\n",
      "        [-1.8802, -1.8995,  0.1414, -1.5091],\n",
      "        [ 1.9102,  1.9210,  2.2253,  1.8771]])\n",
      "The comparison between a tensor and a single value.\n",
      "\n",
      "The element is less than 0.5 \n",
      " tensor([[False, False,  True,  True],\n",
      "        [ True,  True,  True,  True],\n",
      "        [False, False, False, False]])\n",
      "The comparison between two tensors.\n",
      "\n",
      "The comparison result between tesnor a and c \n",
      " tensor([[ True,  True, False, False],\n",
      "        [False, False,  True, False],\n",
      "        [ True,  True,  True,  True]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.randn((3,4))\n",
    "print(\"The original tensor is \\n {}\".format(a))\n",
    "print(\"The comparison between a tensor and a single value.\\n\")\n",
    "b = torch.lt(a, 0.5)\n",
    "print(\"The element is less than 0.5 \\n {}\".format(b))\n",
    "c = torch.randn((3, 4))\n",
    "print(\"The comparison between two tensors.\\n\")\n",
    "d = torch.gt(a, c)\n",
    "print(\"The comparison result between tesnor a and c \\n {}\".format(d))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-24T21:17:00.642506Z",
     "start_time": "2024-04-24T21:17:00.468626Z"
    }
   },
   "id": "f6e628d1cc3495ca",
   "execution_count": 51
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Matrix-Matrix, Matrix-Vector and Vector-Vector Multiplications\n",
    "\n",
    "Matrix vector multiplication can be done using the mv() function or the @ operator.\n",
    "Similarly matrix matrix multiplication can be done using the mm() function or the @ operator.\n",
    "The dot product of two tensors can be calculated using the dot() function.\n",
    "\n",
    "Note:\n",
    "\n",
    "torch.mv requires a 2D tensor and a 1D tensor.\n",
    "torch.mm requires two tensors to have the same dimensions (mm does not broadcast).\n",
    "torch.dot requires the two tensors to be 1D tensors of the same length.\n",
    "torch.matmul can be used for matrix multiplication and matrix-vector multiplication (matmul does broadcast).\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "36bcfb7a2f0b2567"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix: tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "Vector: tensor([1., 1., 2.])\n",
      "Result of matrix-vector multiplication: tensor([4., 4.])\n",
      "Result of matrix-vector multiplication using the @ operator: tensor([4., 4.])\n"
     ]
    }
   ],
   "source": [
    "matrix = torch.ones(2,3) # 2x3 matrix\n",
    "print(\"Matrix:\", matrix)\n",
    "vector = torch.tensor([1, 1, 2], dtype=torch.float32) # dimension must match the number of columns in the matrix\n",
    "print(\"Vector:\", vector)\n",
    "result = torch.mv(matrix, vector) # matrix-vector multiplication, requires float data type\n",
    "print(\"Result of matrix-vector multiplication:\", result)\n",
    "\n",
    "result = matrix @ vector # matrix-vector multiplication using the @ operator\n",
    "print(\"Result of matrix-vector multiplication using the @ operator:\", result)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-24T21:17:00.773736Z",
     "start_time": "2024-04-24T21:17:00.631009Z"
    }
   },
   "id": "afc7bf0ca4e6aa36",
   "execution_count": 52
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix A: tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]]) torch.Size([2, 3])\n",
      "\n",
      "Matrix B: tensor([[1., 1.],\n",
      "        [1., 1.],\n",
      "        [1., 1.]]) torch.Size([3, 2])\n",
      "\n",
      "Result of matrix-matrix multiplication: tensor([[3., 3.],\n",
      "        [3., 3.]])\n",
      "\n",
      "Result of matrix-matrix multiplication using the @ operator: tensor([[3., 3.],\n",
      "        [3., 3.]])\n"
     ]
    }
   ],
   "source": [
    "A = torch.ones(2,3) # 2x3 matrix\n",
    "B = torch.ones(3,2)\n",
    "print(\"Matrix A:\", A, A.shape)\n",
    "print(\"\\nMatrix B:\", B, B.shape)\n",
    "result = torch.mm(A, B)\n",
    "print(\"\\nResult of matrix-matrix multiplication:\", result)\n",
    "result = A @ B\n",
    "print(\"\\nResult of matrix-matrix multiplication using the @ operator:\", result)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-24T21:17:00.803828Z",
     "start_time": "2024-04-24T21:17:00.711872Z"
    }
   },
   "id": "ac961e8b8632c62e",
   "execution_count": 53
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector v: tensor([1., 2., 3., 4.]) torch.Size([4])\n",
      "Vector u: tensor([2., 2., 2., 2.]) torch.Size([4])\n",
      "Result of dot product: tensor(20.)\n"
     ]
    }
   ],
   "source": [
    "v = torch.tensor([1, 2, 3, 4], dtype=torch.float32)\n",
    "print(\"Vector v:\", v, v.shape)\n",
    "u = torch.ones(4) * 2\n",
    "print(\"Vector u:\", u, u.shape)\n",
    "result = torch.dot(v, u) # dot product of two tensors\n",
    "print(\"Result of dot product:\", result)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-24T21:17:00.948871Z",
     "start_time": "2024-04-24T21:17:00.807213Z"
    }
   },
   "id": "25a06f0228de58c7",
   "execution_count": 54
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Loading and Saving Tensors\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4acb9791f0f80147"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded tensor: tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14])\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.arange(0,15)\n",
    "torch.save(tensor, 'tensor.pt') # save the tensor to a file\n",
    "loaded_tensor = torch.load('tensor.pt') # load the tensor from a file\n",
    "print(\"Loaded tensor: {}\".format(loaded_tensor))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-24T21:17:01.075692Z",
     "start_time": "2024-04-24T21:17:00.910466Z"
    }
   },
   "id": "ee830d31e438a337",
   "execution_count": 55
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 3 tensors:\n",
      "\n",
      "[tensor([0, 1, 2, 3, 4]), tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]]), tensor([[0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.]])]\n"
     ]
    }
   ],
   "source": [
    "# Save a list of tensors\n",
    "tensors = [\n",
    "    torch.arange(0, 5),\n",
    "    torch.ones(3, 3),\n",
    "    torch.zeros(5, 5)\n",
    "]\n",
    "torch.save(tensors, 'tensors.pt') # save a list of tensors to a file\n",
    "loaded_tensors = torch.load('tensors.pt') # load the list of tensors from a file\n",
    "print(\"Loaded {} tensors:\\n\\n{}\".format(len(loaded_tensors),loaded_tensors))\n",
    "os.remove('tensors.pt')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-24T21:17:01.174279Z",
     "start_time": "2024-04-24T21:17:01.020241Z"
    }
   },
   "id": "9569717509b88e69",
   "execution_count": 56
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 3 tensors:\n",
      "\n",
      "{'arange': tensor([0, 1, 2, 3, 4]), 'ones': tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]]), 'zeros': tensor([[0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.]])}\n"
     ]
    }
   ],
   "source": [
    "# Save a map of tensors\n",
    "tensors = {\n",
    "    'arange': torch.arange(0, 5),\n",
    "    'ones': torch.ones(3, 3),\n",
    "    'zeros': torch.zeros(5, 5)\n",
    "}\n",
    "torch.save(tensors, 'tensors.pt') # save a list of tensors to a file\n",
    "loaded_tensors = torch.load('tensors.pt') # load the list of tensors from a file\n",
    "print(\"Loaded {} tensors:\\n\\n{}\".format(len(loaded_tensors),loaded_tensors))\n",
    "os.remove('tensors.pt')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-24T21:17:01.235437Z",
     "start_time": "2024-04-24T21:17:01.163208Z"
    }
   },
   "id": "a758e33c0a23d1ce",
   "execution_count": 57
  },
  {
   "cell_type": "markdown",
   "source": [
    "# The Concept of Broadcasting\n",
    "Broadcasting is a powerful mechanism that allows PyTorch to work with tensors of different shapes when performing arithmetic operations.\n",
    "\n",
    "Broadcasting refers to the method used to apply arithmetic operations to arrays of differing shapes. Under specific conditions, the smaller array is \"broadcast\" over the larger one to ensure their shapes are compatible for the operations. Here is an example:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9b0ee03400f09b56"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of tensor A: torch.Size([10, 3, 4])\n",
      "Shape of tensor B: torch.Size([4, 6])\n",
      "Shape of the result tensor: torch.Size([10, 3, 6])\n"
     ]
    }
   ],
   "source": [
    "a = torch.rand([10, 3, 4]) # This tensor can be interpreted as a batch of 10 3x4 matrices\n",
    "b = torch.rand([4, 6])\n",
    "print(\"Shape of tensor A:\", a.shape)\n",
    "print(\"Shape of tensor B:\", b.shape)\n",
    "\"\"\"\n",
    "To perform the matrix multiplication, PyTorch broadcasts the b tensor to match the batch size of a. This means tensor b is implicitly expanded to [10, 4, 6] without actually copying the data but by conceptually replicating b across the batch dimension.\n",
    "\"\"\"\n",
    "result = torch.matmul(a, b) \n",
    "print(\"Shape of the result tensor:\", result.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-24T21:17:01.295361Z",
     "start_time": "2024-04-24T21:17:01.239603Z"
    }
   },
   "id": "cec6635db51324bd",
   "execution_count": 58
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15])"
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor = torch.arange(0,16)\n",
    "tensor"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-24T21:17:01.374944Z",
     "start_time": "2024-04-24T21:17:01.282450Z"
    }
   },
   "id": "dfd7e6b0e7a5eba2",
   "execution_count": 59
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[ 0,  1,  2,  3],\n        [ 4,  5,  6,  7],\n        [ 8,  9, 10, 11],\n        [12, 13, 14, 15]])"
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor.reshape(4, 4) "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-24T21:17:01.465419Z",
     "start_time": "2024-04-24T21:17:01.377525Z"
    }
   },
   "id": "ce2149029798103d",
   "execution_count": 60
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Summary\n",
    "\n",
    "The following is a summary of the most important functions and methods we have learned in this notebook:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "303316ff72743a4"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dtype of my tensor a is: torch.float32\n",
      "The size of my tensor a is: torch.Size([2, 3, 4])\n",
      "The shape of my tensor a is: torch.Size([2, 3, 4])\n",
      "The dims of my tensor a is: 3\n",
      "The dims of my tensor a is: 3\n",
      "The number of elements in my tensor is: 24\n",
      "My tensor is stored on the GPU: False\n",
      "My tensor is stored on device: cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "my_tensor = torch.randn((2, 3, 4), dtype=torch.float)\n",
    "print(\"The dtype of my tensor a is:\", my_tensor.dtype)\n",
    "print(\"The size of my tensor a is:\", my_tensor.size())\n",
    "print(\"The shape of my tensor a is:\", my_tensor.shape)\n",
    "print(\"The dims of my tensor a is:\", my_tensor.dim())\n",
    "print(\"The dims of my tensor a is:\", my_tensor.ndim)\n",
    "print(\"The number of elements in my tensor is:\", my_tensor.numel())\n",
    "print(\"My tensor is stored on the GPU:\", my_tensor.is_cuda)\n",
    "print(\"My tensor is stored on device:\", my_tensor.device)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-24T21:17:01.578939Z",
     "start_time": "2024-04-24T21:17:01.450528Z"
    }
   },
   "id": "e03ac63c7f0b7171",
   "execution_count": 61
  },
  {
   "cell_type": "markdown",
   "source": [
    "PyTorch offers different data types, choosing the right one is important because it will influence the memory usage and\n",
    "the performance (and some PyTorch methods have requirements regarding the datatype of the tensor that is passed into them as an argument).\n",
    "\n",
    "| Data Type              | dtype                      | CPU tensor         | GPU tensor              |\n",
    "|------------------------|----------------------------|--------------------|-------------------------|\n",
    "| 32-bit floating point  | torch.float32/torch.float  | torch.FloatTensor  | torch.cuda.FloatTensor  |\n",
    "| 64-bit floating point  | torch.float64/torch.double | torch.DoubleTensor | torch.cuda.DoubleTensor |\n",
    "| 8-bit integer (signed) | torch.int16                | torch.ShortTensor  | torch.cuda.ShortTensor  |\n",
    "| boolean                | torch.bool                 | torch.BoolTensor   | torch.cuda.BoolTensor   |\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d2465a036ffb1d57"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
