{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# PyTorch Basics - Working with Tensors\n",
    "Some exercises to understand the basics of PyTorch working with tensors"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "aa26a59b7751670"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Creating differnet kinds of tensors from lists and numpy arrays"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fbbbab043f81aa34"
  },
  {
   "cell_type": "code",
   "source": [
    "import torch\n",
    "\n",
    "# Tensors can be created from lists and nested lists:\n",
    "\n",
    "a = torch.tensor([1 ,2, 3]) # 1D tensor\n",
    "b = torch.tensor([[1], [2], [3]]) # 2D tensor\n",
    "\n",
    "print(\"1D tensor A:\", a)\n",
    "print(\"2D tensor B:\", b, \"\\n\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-16T22:54:06.663991Z",
     "start_time": "2024-04-16T22:54:05.087985Z"
    }
   },
   "id": "27cbbde8186509c8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1D tensor A: tensor([1, 2, 3])\n",
      "2D tensor B: tensor([[1],\n",
      "        [2],\n",
      "        [3]]) \n"
     ]
    }
   ],
   "execution_count": 268
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.ones(2, 3) # will throw a type error in numpy\n",
    "b = torch.ones((2, 3)) # works the same in numpy\n",
    "torch.equal(a, b)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-16T22:54:07.018670Z",
     "start_time": "2024-04-16T22:54:06.670051Z"
    }
   },
   "id": "4d0c01ebe67499aa",
   "execution_count": 269
  },
  {
   "cell_type": "code",
   "source": [
    "# inspect the dimension of the tensors\n",
    "print(\"Dimension of tensor A:\", a.dim())\n",
    "print(\"Dimension of tensor B:\", b.dim(), \"\\n\")\n",
    "# inspect the size (==shape) of the tensors\n",
    "print(\"Shape of tensor A:\", a.size())\n",
    "print(\"Shape of tensor B:\", b.shape, \"\\n\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-16T22:54:07.442526Z",
     "start_time": "2024-04-16T22:54:06.905194Z"
    }
   },
   "id": "a76b85d66fe1d604",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimension of tensor A: 2\n",
      "Dimension of tensor B: 2 \n",
      "\n",
      "Shape of tensor A: torch.Size([2, 3])\n",
      "Shape of tensor B: torch.Size([2, 3]) \n"
     ]
    }
   ],
   "execution_count": 270
  },
  {
   "cell_type": "markdown",
   "source": [
    "Note: mytensor.dim() returns len(mytensor.shape) whereas mytensor.shape tells us the number of elements in each dimension"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f601277ae6383d96"
  },
  {
   "cell_type": "code",
   "source": [
    "\n",
    "# inspect the data type of the tensors\n",
    "print(\"Data type of tensor A:\", a.dtype)\n",
    "print(\"Data type of tensor B:\", b.dtype, \"\\n\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-16T22:54:07.891700Z",
     "start_time": "2024-04-16T22:54:07.445894Z"
    }
   },
   "id": "f4b3bfef79126708",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data type of tensor A: torch.float32\n",
      "Data type of tensor B: torch.float32 \n"
     ]
    }
   ],
   "execution_count": 271
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.ones(1,2,3,dtype=torch.long)\n",
    "b = torch.ones((1,2,3), dtype=torch.float32)\n",
    "torch.equal(a, b) # will return true because the values of the tensors are the same"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-16T22:54:08.197642Z",
     "start_time": "2024-04-16T22:54:07.756812Z"
    }
   },
   "id": "9917ba2c30e76096",
   "execution_count": 272
  },
  {
   "cell_type": "code",
   "source": [
    "# Tensors can also be created from NumPy arrays\n",
    "import numpy as np\n",
    "\n",
    "my_np_array = np.array([1, 2, 3])\n",
    "a = torch.tensor(my_np_array) # pass the np array into the tensor function\n",
    "b = torch.from_numpy(my_np_array) # or use the from_numpy function, the result is the same\n",
    "print(\"1D tensor A from numpy array:\", a)\n",
    "print(\"1D tensor B from numpy array:\", b)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-16T22:54:08.385156Z",
     "start_time": "2024-04-16T22:54:08.096752Z"
    }
   },
   "id": "8a2d752a65840dd7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1D tensor A from numpy array: tensor([1, 2, 3])\n",
      "1D tensor B from numpy array: tensor([1, 2, 3])\n"
     ]
    }
   ],
   "execution_count": 273
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Creating special tensors"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3f70c77b66e67d53"
  },
  {
   "cell_type": "code",
   "source": [
    "# creates a 2-dimensional tensor, a 5x5 identity matrix (ones on the diagonal, zeros elsewhere)\n",
    "identity_tensor = torch.eye(5)\n",
    "identity_tensor"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-16T22:54:08.809877Z",
     "start_time": "2024-04-16T22:54:08.389109Z"
    }
   },
   "id": "329b97ae9643f2f0",
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[1., 0., 0., 0., 0.],\n        [0., 1., 0., 0., 0.],\n        [0., 0., 1., 0., 0.],\n        [0., 0., 0., 1., 0.],\n        [0., 0., 0., 0., 1.]])"
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 274
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-16T22:54:09.005327Z",
     "start_time": "2024-04-16T22:54:08.731484Z"
    }
   },
   "id": "1a36b647302f7af7",
   "execution_count": 274
  },
  {
   "cell_type": "code",
   "source": [
    "zero_tensor = torch.zeros(3, 10) # creates a 2-dimensional tensor, a 3x10 matrix filled with zeros\n",
    "zero_tensor"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-16T22:54:09.401348Z",
     "start_time": "2024-04-16T22:54:09.009393Z"
    }
   },
   "id": "2365ece098efc413",
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])"
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 275
  },
  {
   "cell_type": "code",
   "source": [
    "ones_tensor = torch.ones(5, 2) # creates a 2-dimensional tensor, a 5x2 matrix filled with ones\n",
    "ones_tensor"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-16T22:54:09.540324Z",
     "start_time": "2024-04-16T22:54:09.295719Z"
    }
   },
   "id": "2f8a8616023e2dd4",
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[1., 1.],\n        [1., 1.],\n        [1., 1.],\n        [1., 1.],\n        [1., 1.]])"
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 276
  },
  {
   "cell_type": "markdown",
   "source": [
    "# We can also create a null value tensor'python"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1b85125cd0923b00"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Note: with any of the above functions, you can specify multiple parameters to create tensors of higher dimensions (in the examples we only created 2D tensors)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "226e4a6cfddc8c0b"
  },
  {
   "cell_type": "code",
   "source": [
    "random_tensor = torch.rand(2, 2, 3) # creates a 2-dimensional tensor, a 3x4 matrix filled with random numbers between 0 and 1\n",
    "random_tensor"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-16T22:54:09.857316Z",
     "start_time": "2024-04-16T22:54:09.543930Z"
    }
   },
   "id": "bac84fb0bbb10c7c",
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[[0.6188, 0.8601, 0.8451],\n         [0.3656, 0.2883, 0.0914]],\n\n        [[0.9781, 0.6543, 0.3710],\n         [0.9317, 0.5223, 0.3185]]])"
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 277
  },
  {
   "cell_type": "code",
   "source": [
    "random_normal_tensor = torch.randn(20) # creates a 1-dimensional tensor, a 20-element vector filled with random numbers from a normal distribution\n",
    "random_normal_tensor"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-16T22:54:10.132002Z",
     "start_time": "2024-04-16T22:54:09.838812Z"
    }
   },
   "id": "ba05d7d470e386ba",
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([-0.7830,  1.7117,  0.3867, -0.1079,  0.9336,  0.2121,  0.0946,  2.1931,\n        -1.2770, -0.8225,  0.4470, -0.3557,  0.1073,  0.8473, -0.3351,  0.2986,\n         2.0060,  1.0127,  0.3759, -0.4973])"
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 278
  },
  {
   "cell_type": "markdown",
   "source": [
    "Reminder: Normal distribution means that the mean is 0 and the variance is 1"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fb51294d1344527a"
  },
  {
   "cell_type": "code",
   "source": [
    "# we can also create a tensor filled with random integers\n",
    "random_int_tensor = torch.randint(low=5, high=10, size=(5, 5)) # creates a 2-dimensional tensor, a 5x5 matrix filled with random integers between 0 and 10\n",
    "random_int_tensor"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-16T22:54:10.470403Z",
     "start_time": "2024-04-16T22:54:10.048357Z"
    }
   },
   "id": "488a63bddd00ac8b",
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[8, 9, 9, 5, 6],\n        [9, 6, 8, 6, 6],\n        [9, 6, 5, 5, 9],\n        [7, 5, 6, 7, 5],\n        [5, 6, 5, 7, 9]])"
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 279
  },
  {
   "cell_type": "code",
   "source": [
    "# pytorch also allows to create a tensor filled with a range of numbers\n",
    "range_tensor = torch.arange(3, 17) # creates a 1-dimensional tensor, a 14-element vector filled with numbers from 3 to 16\n",
    "range_tensor"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-16T22:54:10.954563Z",
     "start_time": "2024-04-16T22:54:10.459673Z"
    }
   },
   "id": "6a4efc8781c28a57",
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([ 3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16])"
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 280
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Working with tensor metadata\n",
    "\n",
    "We alredy learned about .dim() .shape and .dtype. Here are some more useful tensor attributes:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5703b4ac2b238ede"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-16T22:54:11.198427Z",
     "start_time": "2024-04-16T22:54:10.750368Z"
    }
   },
   "cell_type": "code",
   "source": [
    "my_tensor = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
    "print(my_tensor.numel()) # returns the number of elements in the tensor\n",
    "print(my_tensor.nelement())"
   ],
   "id": "8a67835fe5ae24a1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n",
      "9\n"
     ]
    }
   ],
   "execution_count": 281
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-16T22:54:11.602497Z",
     "start_time": "2024-04-16T22:54:11.097443Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "False"
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 282,
   "source": [
    "# Check if cuda is enabled\n",
    "my_tensor.is_cuda # returns true if the tensor is stored on the GPU"
   ],
   "id": "33a82c7bf4e4f65c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-16T22:54:11.805346Z",
     "start_time": "2024-04-16T22:54:11.514001Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Get the device on which the tensor is stored on (you could have multiple GPUs)\n",
    "my_tensor.device"
   ],
   "id": "78b2ffadd6da5b06",
   "outputs": [
    {
     "data": {
      "text/plain": "device(type='cpu')"
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 283
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Tensor Types and Casting\n",
    "\n",
    "PyTorch defines its own data type, which can be used to create tensors. The default data type is float32. You can change the data type of the tensor using the .to() method. \n",
    "\n",
    "\n",
    "| Data Type                | dtype                       | CPU tensor       | GPU tensor              |\n",
    "|--------------------------|-----------------------------|------------------|-------------------------|\n",
    "| 32-bit floating point    | torch.float32/torch.float   | torch.FloatTensor| torch.cuda.FloatTensor  |\n",
    "| 64-bit floating point    | torch.float64/torch.double  | torch.DoubleTensor| torch.cuda.DoubleTensor|\n",
    "| 8-bit integer (signed)   | torch.int16                 | torch.ShortTensor| torch.cuda.ShortTensor  |\n",
    "| boolean                  | torch.bool                  | torch.BoolTensor | torch.cuda.BoolTensor   |\n",
    "\n",
    "\n"
   ],
   "id": "3607fd9fbd80f0d1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-16T22:54:12.129734Z",
     "start_time": "2024-04-16T22:54:11.742179Z"
    }
   },
   "cell_type": "code",
   "source": [
    "my_tensor = torch.tensor([1, 1, 1, 1])\n",
    "print(\"The dtype of my_tensor is {}\".format(my_tensor.dtype))\n",
    "\n",
    "my_tensor = torch.tensor([1, 2, 3, 4], dtype=torch.float)\n",
    "print(\"The dtype of my_tensor is {}\".format(my_tensor.dtype))"
   ],
   "id": "f8a81d53456fce2d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dtype of my_tensor is torch.int64\n",
      "The dtype of my_tensor is torch.float32\n"
     ]
    }
   ],
   "execution_count": 284
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-16T22:54:12.306123Z",
     "start_time": "2024-04-16T22:54:12.046685Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float32\n",
      "torch.int32\n",
      "torch.float64\n",
      "torch.int64\n"
     ]
    }
   ],
   "execution_count": 285,
   "source": [
    "# Pytorch has some conevience methods to create tensors with a specific data type\n",
    "tensor_float32 = torch.FloatTensor([1, 2, 3, 4])\n",
    "print(tensor_float32.dtype)\n",
    "tensor_int32 = torch.IntTensor([1, 2, 3, 4])\n",
    "print(tensor_int32.dtype)\n",
    "tensor_float64 = torch.DoubleTensor([1, 2, 3, 4])\n",
    "print(tensor_float64.dtype)\n",
    "tensor_int64 = torch.LongTensor([1, 2, 3, 4])\n",
    "print(tensor_int64.dtype)"
   ],
   "id": "2c819908912709df"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.int32\n",
      "torch.float32\n"
     ]
    }
   ],
   "source": [
    "# Casting tensors to a different data type by calling the .to() method on the tensor\n",
    "tensor = tensor_float32.to(dtype=torch.int32)\n",
    "print(tensor.dtype)\n",
    "tensor = tensor.to(dtype=torch.float32)\n",
    "print(tensor.dtype)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-16T22:54:12.567446Z",
     "start_time": "2024-04-16T22:54:12.236001Z"
    }
   },
   "id": "29bf56cff6f22c7",
   "execution_count": 286
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAssertionError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[287], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# It is possible to cast tensors to different devices (CPU or GPU)\u001B[39;00m\n\u001B[0;32m----> 2\u001B[0m tensor \u001B[38;5;241m=\u001B[39m \u001B[43mtensor\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mto\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdevice\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mcuda\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/projects/LLM-FastTrack/.venv/lib/python3.11/site-packages/torch/cuda/__init__.py:293\u001B[0m, in \u001B[0;36m_lazy_init\u001B[0;34m()\u001B[0m\n\u001B[1;32m    288\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\n\u001B[1;32m    289\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCannot re-initialize CUDA in forked subprocess. To use CUDA with \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    290\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmultiprocessing, you must use the \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mspawn\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m start method\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    291\u001B[0m     )\n\u001B[1;32m    292\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(torch\u001B[38;5;241m.\u001B[39m_C, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_cuda_getDeviceCount\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[0;32m--> 293\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mAssertionError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTorch not compiled with CUDA enabled\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    294\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m _cudart \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    295\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mAssertionError\u001B[39;00m(\n\u001B[1;32m    296\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlibcudart functions unavailable. It looks like you have a broken build?\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    297\u001B[0m     )\n",
      "\u001B[0;31mAssertionError\u001B[0m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "source": [
    "# It is possible to cast tensors to different devices (CPU or GPU)\n",
    "tensor = tensor.to(device='cuda')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-16T22:54:13.056742Z",
     "start_time": "2024-04-16T22:54:12.576792Z"
    }
   },
   "id": "e6ab4b0daea5f5dd",
   "execution_count": 287
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Or better: :)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "tensor = tensor.to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-16T22:54:13.256240Z",
     "start_time": "2024-04-16T22:54:12.808845Z"
    }
   },
   "id": "866e80d4395b5e06",
   "execution_count": 288
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Selecting Elements from a Tensor\n",
    "\n",
    "This works similar to numpy arrays"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9949462e15c97da5"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original tensor: tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15])\n",
      "Reshaped tensor: tensor([[ 0,  1,  2,  3],\n",
      "        [ 4,  5,  6,  7],\n",
      "        [ 8,  9, 10, 11],\n",
      "        [12, 13, 14, 15]])\n"
     ]
    }
   ],
   "source": [
    "# reshape a 1D tensor to a 2D tensor\n",
    "tensor = torch.arange(0, 16)\n",
    "print(\"Original tensor:\", tensor)\n",
    "tensor = tensor.reshape((4, 4)) # the product of the dimensions must be equal to the number of elements in the tensor\n",
    "print(\"Reshaped tensor:\", tensor)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-16T22:54:18.253416Z",
     "start_time": "2024-04-16T22:54:13.166815Z"
    }
   },
   "id": "b5077047d8208e56",
   "execution_count": 289
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0) tensor(1) tensor(2) tensor(3) \n",
      "tensor(4) tensor(5) tensor(6) tensor(7) \n",
      "tensor(8) tensor(9) tensor(10) tensor(11) \n",
      "tensor(12) tensor(13) tensor(14) tensor(15) \n"
     ]
    }
   ],
   "source": [
    "for i in range(tensor.shape[0]):\n",
    "    for j in range(tensor.shape[1]):\n",
    "        print(tensor[i, j], end=\" \")\n",
    "    print()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-16T22:54:18.520772Z",
     "start_time": "2024-04-16T22:54:18.183938Z"
    }
   },
   "id": "90bc452a1cf10638",
   "execution_count": 290
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First row: tensor([0, 1, 2, 3])\n",
      "Seocnd column: tensor([ 1,  5,  9, 13])\n"
     ]
    }
   ],
   "source": [
    "# One can even select rows and columns (!)\n",
    "print(\"First row:\",tensor[0, :]) # select the first row\n",
    "print(\"Seocnd column:\", tensor[:, 1]) # select the first column"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-16T22:54:18.956634Z",
     "start_time": "2024-04-16T22:54:18.455508Z"
    }
   },
   "id": "742e4005343c67eb",
   "execution_count": 291
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Selecting elements from a tensor with index_select\n",
    "This allows us to select elements from a tensor based on the indices we provide"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4d918e49882d2b7a"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0,  1,  2,  3],\n",
      "        [ 4,  5,  6,  7],\n",
      "        [ 8,  9, 10, 11],\n",
      "        [12, 13, 14, 15]])\n",
      "tensor([[ 0,  3],\n",
      "        [ 4,  7],\n",
      "        [ 8, 11],\n",
      "        [12, 15]])\n",
      "tensor([[ 0,  1,  2,  3],\n",
      "        [12, 13, 14, 15]])\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.arange(0, 16).reshape((4,4))\n",
    "indices = torch.tensor([0, 3]) # select the first and last column \n",
    "columns = tensor.index_select(dim=1, index=indices) # dim = 0 for rows, dim is the dimension in which we index\n",
    "rows =  tensor.index_select(dim=0, index=indices) # dim = 1 for columns, dim is the dimension in which we index\n",
    "print(tensor)\n",
    "print(columns)\n",
    "print(rows)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-16T22:54:19.264304Z",
     "start_time": "2024-04-16T22:54:18.962281Z"
    }
   },
   "id": "6c14aff9553fe17c",
   "execution_count": 292
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0,  1,  2,  3],\n",
      "        [ 4,  5,  6,  7],\n",
      "        [ 8,  9, 10, 11],\n",
      "        [12, 13, 14, 15]]) \n",
      "\n",
      "tensor(5) \n",
      "\n",
      "tensor([ 8,  9, 10, 11]) \n",
      "\n",
      "tensor([[ 0],\n",
      "        [ 4],\n",
      "        [ 8],\n",
      "        [12]]) \n",
      "\n",
      "tensor([[ 8,  9],\n",
      "        [12, 13]]) \n",
      "\n",
      "tensor([[2, 3],\n",
      "        [6, 7]]) \n"
     ]
    }
   ],
   "source": [
    "tensor = torch.arange(0,16).reshape(4,4)\n",
    "print(tensor,\"\\n\")\n",
    "print(tensor[1,1],\"\\n\") # select a single element\n",
    "print(tensor[2,:],\"\\n\") # select a row\n",
    "print(tensor[:,0].reshape(4,1),\"\\n\") # select a column\n",
    "print(tensor[2:,:2],\"\\n\") # select the lower bottom submatrix (row 3 and 4, column 1 and 2)\n",
    "print(tensor[0:2,2:4],\"\\n\") # select the top right submatrix (row 0 and 1, column 2 to 3)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-16T22:54:19.607113Z",
     "start_time": "2024-04-16T22:54:19.199346Z"
    }
   },
   "id": "176dd097d6145f80",
   "execution_count": 293
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Selecting elements from a Tensor with a mask\n",
    "This is pretty cool, we can create a BoolTensor as a mask to select which elements we want to select from a tensor. "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d657d6d90c8e67ab"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 1, 2],\n",
      "        [3, 4, 5],\n",
      "        [6, 7, 8]])\n",
      "tensor([[ True, False,  True],\n",
      "        [False,  True, False],\n",
      "        [ True, False,  True]])\n",
      "tensor([0, 2, 4, 6, 8])\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.arange(0, 9).reshape((3,3))\n",
    "print(tensor)\n",
    "mask = torch.BoolTensor([\n",
    "    [1, 0, 1],  # 1 or True means we select the element\n",
    "    [0, 1, 0], \n",
    "    [1, 0, True]\n",
    "])\n",
    "# Alternative way of defining the mask: mask = torch.BoolTensor([1, 0, 1, 0, 1, 1, 1, 0, 1]).reshape(3,3)\n",
    "print(mask)\n",
    "selection = torch.masked_select(tensor, mask) # returns a 1D tensor with the elements that are True in the mask\n",
    "print(selection)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-16T22:54:19.744015Z",
     "start_time": "2024-04-16T22:54:19.604541Z"
    }
   },
   "id": "3b267d4bdbe673f0",
   "execution_count": 294
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Reshaping Tensors"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a224cd569b722cd1"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original tensor: tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15],\n",
      "       dtype=torch.int8)\n",
      "Shape of the original tensor: torch.Size([16])\n",
      "Reshaped tensor: tensor([[ 0,  1,  2,  3],\n",
      "        [ 4,  5,  6,  7],\n",
      "        [ 8,  9, 10, 11],\n",
      "        [12, 13, 14, 15]], dtype=torch.int8)\n",
      "Shape of the reshaped tensor: torch.Size([4, 4])\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.arange(0, 16, dtype=torch.int8)\n",
    "print(\"Original tensor:\", tensor)\n",
    "print(\"Shape of the original tensor:\", tensor.shape)\n",
    "tensor = torch.reshape(tensor, (4,4))\n",
    "# or tensor = tensor.reshape((4,4))\n",
    "print(\"Reshaped tensor:\", tensor)\n",
    "print(\"Shape of the reshaped tensor:\", tensor.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-16T22:54:19.870745Z",
     "start_time": "2024-04-16T22:54:19.725443Z"
    }
   },
   "id": "93e47030cafbf0b6",
   "execution_count": 295
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reshaped tensor: tensor([[ 0,  1],\n",
      "        [ 2,  3],\n",
      "        [ 4,  5],\n",
      "        [ 6,  7],\n",
      "        [ 8,  9],\n",
      "        [10, 11],\n",
      "        [12, 13],\n",
      "        [14, 15]], dtype=torch.int8)\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.reshape(tensor, (-1, 2)) # the -1 is a placeholder for the dimension that is inferred from the length of the tensor and the other dimensions\n",
    "print(\"Reshaped tensor:\", tensor)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-16T22:54:19.954393Z",
     "start_time": "2024-04-16T22:54:19.874324Z"
    }
   },
   "id": "c103b67e2695b182",
   "execution_count": 296
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Squeeze and un-squeeze\n",
    "\n",
    "Allows us to remove and add dimensions of size 1 to a tensor.\n",
    "In numpy expand_dims() and squeeze() are used for the same purpose."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9c994a1b06b0b856"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original tensor: tensor([[[ 0,  1,  2,  3],\n",
      "         [ 4,  5,  6,  7],\n",
      "         [ 8,  9, 10, 11],\n",
      "         [12, 13, 14, 15]]])\n",
      "Shape of the original tensor: torch.Size([1, 4, 4])\n",
      "\n",
      "Squeezed tensor: tensor([[ 0,  1,  2,  3],\n",
      "        [ 4,  5,  6,  7],\n",
      "        [ 8,  9, 10, 11],\n",
      "        [12, 13, 14, 15]])\n",
      "Shape of the squeezed tensor: torch.Size([4, 4])\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.arange(0, 16).reshape((1, 4, 4))\n",
    "print(\"Original tensor:\", tensor)\n",
    "print(\"Shape of the original tensor:\", tensor.shape)\n",
    "tensor = torch.squeeze(tensor) # removes all dimensions with size 1\n",
    "print(\"\\nSqueezed tensor:\", tensor)\n",
    "print(\"Shape of the squeezed tensor:\", tensor.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-16T22:54:20.070186Z",
     "start_time": "2024-04-16T22:54:19.936900Z"
    }
   },
   "id": "69d9aeffbfe029ce",
   "execution_count": 297
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original tensor: tensor([[ 0,  1,  2,  3],\n",
      "        [ 4,  5,  6,  7],\n",
      "        [ 8,  9, 10, 11],\n",
      "        [12, 13, 14, 15]])\n",
      "Shape of the original tensor: torch.Size([4, 4])\n",
      "\n",
      "Un-squeezed tensor: tensor([[[ 0,  1,  2,  3]],\n",
      "\n",
      "        [[ 4,  5,  6,  7]],\n",
      "\n",
      "        [[ 8,  9, 10, 11]],\n",
      "\n",
      "        [[12, 13, 14, 15]]])\n",
      "Shape of the un-squeezed tensor: torch.Size([4, 1, 4])\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.arange(0, 16).reshape((4, 4))\n",
    "print(\"Original tensor:\", tensor)\n",
    "print(\"Shape of the original tensor:\", tensor.shape)\n",
    "tensor = torch.unsqueeze(tensor, 1) # adds a dimension at the specified index\n",
    "print(\"\\nUn-squeezed tensor:\", tensor)\n",
    "print(\"Shape of the un-squeezed tensor:\", tensor.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-16T22:54:20.161895Z",
     "start_time": "2024-04-16T22:54:20.073207Z"
    }
   },
   "id": "337660c828f10657",
   "execution_count": 298
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the original tensor: torch.Size([3, 1, 2, 1, 2])\n",
      "Shape of the squeezed tensor: torch.Size([3, 2, 1, 2])\n",
      "Shape of the squeezed tensor: torch.Size([3, 2, 2])\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.ones((3,1,2,1,2))\n",
    "print(\"Shape of the original tensor:\", tensor.shape)\n",
    "tensor = torch.squeeze(tensor, dim=1) # will only work on dimensions of size 1 (in this case the second dimension)\n",
    "print(\"Shape of the squeezed tensor:\", tensor.shape)\n",
    "tensor = torch.squeeze(tensor) # remove all remaining dimensions of size 1\n",
    "print(\"Shape of the squeezed tensor:\", tensor.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-16T22:54:20.234984Z",
     "start_time": "2024-04-16T22:54:20.122233Z"
    }
   },
   "id": "f1004f60ec1a0011",
   "execution_count": 299
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Transposing Tensors"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "60a16083cb5c8f0c"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original tensor: tensor([[1, 2],\n",
      "        [0, 1]])\n",
      "\n",
      "Transposed tensor: tensor([[1, 0],\n",
      "        [2, 1]])\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.tensor([[1,2], [0,1]])\n",
    "print(\"Original tensor:\", tensor)\n",
    "tensor = torch.transpose(tensor, 0, 1) # swaps the dimensions at index 0 and 1\n",
    "print(\"\\nTransposed tensor:\", tensor)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-16T22:54:20.292732Z",
     "start_time": "2024-04-16T22:54:20.217189Z"
    }
   },
   "id": "2955998781131203",
   "execution_count": 300
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the original tensor: torch.Size([2, 3])\n",
      "Shape of the transposed tensor: torch.Size([3, 2])\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.zeros(2,3)\n",
    "print(\"Shape of the original tensor:\", tensor.shape)\n",
    "tensor = torch.transpose(tensor, 0, 1) # swaps the dimensions at index 0 and 1\n",
    "print(\"Shape of the transposed tensor:\", tensor.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-16T22:54:20.421859Z",
     "start_time": "2024-04-16T22:54:20.297141Z"
    }
   },
   "id": "943b42b0086a671b",
   "execution_count": 301
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Concatenating Tensors"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cc6acd1075a10233"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0.],\n",
      "        [0., 0.]])\n",
      "tensor([[1., 1.],\n",
      "        [1., 1.]])\n",
      "tensor([[0., 0., 1., 1.],\n",
      "        [0., 0., 1., 1.]])\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.],\n",
      "        [1., 1.],\n",
      "        [1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.zeros(2,2)\n",
    "b = torch.ones(2,2)\n",
    "c = torch.concat([a, b], dim=1) # concat along the columns\n",
    "d = torch.concat([a, b], dim=0) # concat along the rows\n",
    "print(a)\n",
    "print(b)\n",
    "print(c)\n",
    "print(d)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-16T22:54:20.442475Z",
     "start_time": "2024-04-16T22:54:20.411231Z"
    }
   },
   "id": "9becb5dd1d70f3cd",
   "execution_count": 302
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Stacking Tensors\n",
    "\n",
    "Using torch.cat() and torch.stack().\n",
    "torch.cat() stacks tensors along an existing dimension, whereas torch.stack() stacks tensors along a new dimension."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f987e78ed3bef168"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor A: tensor([[1., 1.],\n",
      "        [1., 1.]])\n",
      "Shape of tensor A: torch.Size([2, 2])\n",
      "\n",
      "Tensor B: tensor([[0., 0.],\n",
      "        [0., 0.]])\n",
      "Shape of tensor B: torch.Size([2, 2])\n",
      "\n",
      "Stacked tensor: tensor([[[1., 1.],\n",
      "         [1., 1.]],\n",
      "\n",
      "        [[0., 0.],\n",
      "         [0., 0.]]])\n",
      "Shape of the stacked tensor: torch.Size([2, 2, 2])\n",
      "\n",
      "Concatenated tensor: tensor([[1., 1.],\n",
      "        [1., 1.],\n",
      "        [0., 0.],\n",
      "        [0., 0.]])\n",
      "Shape of the concatenated tensor: torch.Size([4, 2])\n",
      "\n",
      "Concatenated tensor: tensor([[1., 1., 0., 0.],\n",
      "        [1., 1., 0., 0.]])\n",
      "Shape of the concatenated tensor: torch.Size([2, 4])\n"
     ]
    }
   ],
   "source": [
    "a = torch.ones(2,2)\n",
    "b = torch.zeros(2,2)\n",
    "print(\"Tensor A:\", a)\n",
    "print(\"Shape of tensor A:\", a.shape)\n",
    "print(\"\\nTensor B:\", b)\n",
    "print(\"Shape of tensor B:\", b.shape)\n",
    "c = torch.stack([a, b], dim=0) # stack along a new dimension\n",
    "print(\"\\nStacked tensor:\", c)\n",
    "print(\"Shape of the stacked tensor:\", c.shape)\n",
    "d = torch.cat([a, b], dim=0) # concatenate along an existing dimension (here: rows)\n",
    "print(\"\\nConcatenated tensor:\", d)\n",
    "print(\"Shape of the concatenated tensor:\", d.shape)\n",
    "e = torch.cat([a, b], dim=1) # concatenate along an existing dimension (here: rows)\n",
    "print(\"\\nConcatenated tensor:\", e)\n",
    "print(\"Shape of the concatenated tensor:\", e.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-16T22:54:20.553929Z",
     "start_time": "2024-04-16T22:54:20.447374Z"
    }
   },
   "id": "aa86e977b71d2d5",
   "execution_count": 303
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Element-wise operations on tensors"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c0bdb66c356bf0cc"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original tensor: tensor([1, 2, 3])\n",
      "Tensor after adding 2 to each element: tensor([3, 4, 5])\n",
      "Tensor after multiplying each element by 2: tensor([ 6,  8, 10])\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.tensor([1,2,3])\n",
    "print(\"Original tensor:\", tensor)\n",
    "tensor += 1 # this adds 1 to each element of the tensor in-place\n",
    "tensor.add(1) # this returns a new tensor, add does not change the original tensor in-place\n",
    "tensor.add_(1) # this however changes the original tensor in-place (same as tensor += 1)\n",
    "print(\"Tensor after adding 2 to each element:\", tensor)\n",
    "tensor *= 2 \n",
    "print(\"Tensor after multiplying each element by 2:\", tensor)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-16T22:54:20.589632Z",
     "start_time": "2024-04-16T22:54:20.531754Z"
    }
   },
   "id": "55a2bafd2ab176bc",
   "execution_count": 304
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor A: tensor([[0, 1],\n",
      "        [2, 3]])\n",
      "Tensor B: tensor([[2., 2.],\n",
      "        [2., 2.]])\n",
      "Tensor C: tensor([[2., 3.],\n",
      "        [4., 5.]])\n",
      "Tensor D: tensor([[0., 2.],\n",
      "        [4., 6.]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.arange(0, 4).reshape(2, 2)\n",
    "b = torch.ones(2,2).reshape(2, 2)\n",
    "b += 1\n",
    "c = a + b # element-wise addition\n",
    "d = a * b # element-wise multiplication\n",
    "print(\"Tensor A:\", a)\n",
    "print(\"Tensor B:\", b)\n",
    "print(\"Tensor C:\", c)\n",
    "print(\"Tensor D:\", d)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-16T22:54:20.719367Z",
     "start_time": "2024-04-16T22:54:20.595552Z"
    }
   },
   "id": "cf02961006ffe33d",
   "execution_count": 305
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Reduction operations on tensors and comparison operations"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ff58250859f94e30"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# TODO continue here"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-16T22:54:20.810918Z",
     "start_time": "2024-04-16T22:54:20.704628Z"
    }
   },
   "id": "969e417faf02c57d",
   "execution_count": 306
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Broadcasting tensors\n",
    "Broadcasting is a powerful mechanism that allows PyTorch to work with tensors of different shapes when performing arithmetic operations."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9b0ee03400f09b56"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#TODO show broadcasting example"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-16T22:54:20.869955Z",
     "start_time": "2024-04-16T22:54:20.814798Z"
    }
   },
   "id": "cec6635db51324bd",
   "execution_count": 307
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15])"
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor = torch.arange(0,16)\n",
    "tensor"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-16T22:54:20.908836Z",
     "start_time": "2024-04-16T22:54:20.852115Z"
    }
   },
   "id": "dfd7e6b0e7a5eba2",
   "execution_count": 308
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[ 0,  1,  2,  3],\n        [ 4,  5,  6,  7],\n        [ 8,  9, 10, 11],\n        [12, 13, 14, 15]])"
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor.reshape(4, 4) "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-16T22:54:20.949257Z",
     "start_time": "2024-04-16T22:54:20.914052Z"
    }
   },
   "id": "ce2149029798103d",
   "execution_count": 309
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Summary\n",
    "\n",
    "TODO: Add summary"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "303316ff72743a4"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dtype of my tensor a is: torch.float32\n",
      "The size of my tensor a is: torch.Size([2, 3, 4])\n",
      "The shape of my tensor a is: torch.Size([2, 3, 4])\n",
      "The dims of my tensor a is: 3\n",
      "The dims of my tensor a is: 3\n",
      "The number of elements in my tensor is: 24\n",
      "My tensor is stored on the GPU: False\n",
      "My tensor is stored on device: cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "my_tensor = torch.randn((2, 3, 4), dtype=torch.float)\n",
    "print(\"The dtype of my tensor a is:\", my_tensor.dtype)\n",
    "print(\"The size of my tensor a is:\", my_tensor.size())\n",
    "print(\"The shape of my tensor a is:\", my_tensor.shape)\n",
    "print(\"The dims of my tensor a is:\", my_tensor.dim())\n",
    "print(\"The dims of my tensor a is:\", my_tensor.ndim)\n",
    "print(\"The number of elements in my tensor is:\", my_tensor.numel())\n",
    "print(\"My tensor is stored on the GPU:\", my_tensor.is_cuda)\n",
    "print(\"My tensor is stored on device:\", my_tensor.device)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-16T22:54:21.019475Z",
     "start_time": "2024-04-16T22:54:20.937587Z"
    }
   },
   "id": "e03ac63c7f0b7171",
   "execution_count": 310
  },
  {
   "cell_type": "markdown",
   "source": [
    "PyTorch offers different data types, choosing the right one is important because it will influence the memory usage and\n",
    "the performance (and some PyTorch methods have requirements regarding the datatype of the tensor that is passed into them as an argument).\n",
    "\n",
    "| Data Type              | dtype                      | CPU tensor         | GPU tensor              |\n",
    "|------------------------|----------------------------|--------------------|-------------------------|\n",
    "| 32-bit floating point  | torch.float32/torch.float  | torch.FloatTensor  | torch.cuda.FloatTensor  |\n",
    "| 64-bit floating point  | torch.float64/torch.double | torch.DoubleTensor | torch.cuda.DoubleTensor |\n",
    "| 8-bit integer (signed) | torch.int16                | torch.ShortTensor  | torch.cuda.ShortTensor  |\n",
    "| boolean                | torch.bool                 | torch.BoolTensor   | torch.cuda.BoolTensor   |\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d2465a036ffb1d57"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
